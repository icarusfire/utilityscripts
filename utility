# ============================================================
# release_lookup.py  —  unified loader (.doc/.docx) + parser
# ============================================================
#
#  • load_docx_any() detects legacy .doc and converts via pypandoc
#  • parse_release_table() extracts the multi‑page Confluence table
#  • get_squad_name() queries by Branch Date
#
# Unit‑tests below monkey‑patch pypandoc.convert_file so the suite
# runs without the actual pandoc binary.
# ============================================================

from __future__ import annotations

from datetime import datetime
from typing import Tuple, Optional, Dict, List
import os
import re
import shutil
import tempfile

import pandas as pd
from docx import Document
from docx.opc.exceptions import PackageNotFoundError

# ---------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------
TARGET_PREFIXES: Tuple[str, ...] = (
    "Release Version",
    "RT Driver Squad",
    "Branch Date",
)

# ---------------------------------------------------------------------
# Utility helpers
# ---------------------------------------------------------------------
def _normalise(text: str) -> str:
    """Lower‑case *text* and strip ALL whitespace."""
    return re.sub(r"\s+", "", text.lower())


def _match_required_prefixes(
    header_cells: List[str], prefixes: Tuple[str, ...]
) -> Optional[Dict[str, int]]:
    """
    Map canonical *prefix* → column_index when each prefix is present
    (case‑ & whitespace‑insensitive starts‑with). Otherwise return *None*.
    """
    prefix_to_index: Dict[str, int] = {}
    norm_headers = [_normalise(c) for c in header_cells]
    norm_to_canonical = {_normalise(p): p for p in prefixes}

    for col_idx, norm_header in enumerate(norm_headers):
        for norm_prefix, canonical in norm_to_canonical.items():
            if norm_header.startswith(norm_prefix):
                prefix_to_index[canonical] = col_idx
                break

    return prefix_to_index if len(prefix_to_index) == len(prefixes) else None


# ---------------------------------------------------------------------
# Loader layer (I/O boundary)
# ---------------------------------------------------------------------
def _convert_with_pandoc(src_doc: str) -> str:
    """
    Convert legacy *.doc* file to *.docx* using pypandoc.
    Returns the path to a temporary .docx file.
    """
    try:
        import pypandoc  # local import to keep top‑level requirements minimal
    except ModuleNotFoundError as exc:
        raise RuntimeError(
            "pypandoc is required to convert .doc files but is not installed. "
            "Install with `pip install pypandoc` or convert files manually."
        ) from exc

    dst_path = tempfile.mktemp(suffix=".docx")
    # pypandoc returns the output path on success
    pypandoc.convert_file(src_doc, "docx", outputfile=dst_path)
    return dst_path


def load_docx_any(path: str) -> Document:
    """
    Load a Word document from *path*.
    • .docx → open directly.
    • .doc  → convert via pypandoc then open.
    """
    if not os.path.isfile(path):
        raise FileNotFoundError(path)

    ext = os.path.splitext(path)[1].lower()
    docx_path = path

    if ext == ".doc":
        docx_path = _convert_with_pandoc(path)

    try:
        return Document(docx_path)
    except PackageNotFoundError as exc:
        raise ValueError(
            f"{path} exists but is not a valid Word file "
            f"or the conversion failed ({exc})"
        ) from None


def read_release_table(path: str) -> pd.DataFrame:
    """
    Convenience façade: load from disk (any extension) then parse.
    """
    return parse_release_table(load_docx_any(path))


# ---------------------------------------------------------------------
# Core parser (pure function)
# ---------------------------------------------------------------------
def parse_release_table(
    document: Document, prefixes: Tuple[str, ...] = TARGET_PREFIXES
) -> pd.DataFrame:
    """
    Extract rows from all tables in *document* that contain all *prefixes*.
    Header matching ignores case and whitespace. Rows from multiple tables
    are concatenated.
    """
    if not document.tables:
        raise ValueError("Document contains no tables.")

    rows: List[Dict[str, str]] = []

    for table in document.tables:
        if not table.rows:
            continue

        header_cells = [c.text.strip() for c in table.rows[0].cells]
        prefix_to_index = _match_required_prefixes(header_cells, prefixes)
        if prefix_to_index is None:
            continue  # table missing required headers — skip

        for row in table.rows[1:]:
            rows.append(
                {
                    prefix: row.cells[prefix_to_index[prefix]].text.strip()
                    for prefix in prefixes
                }
            )

    if not rows:
        raise ValueError("No tables with the required columns were found.")

    df = pd.DataFrame(rows)
    df["Branch Date"] = pd.to_datetime(df["Branch Date"], format="%d %b %Y", errors="coerce")
    df.dropna(subset=["Branch Date"], inplace=True)
    return df


# ---------------------------------------------------------------------
# Query helper
# ---------------------------------------------------------------------
def get_squad_name(
    df: pd.DataFrame, branch_date: str | datetime
) -> Optional[Tuple[str, str]]:
    """
    Return (RT Driver Squad, Release Version) for *branch_date*, or None.
    """
    date_norm = (
        pd.to_datetime(branch_date, format="%d %b %Y")
        if isinstance(branch_date, str)
        else pd.to_datetime(branch_date)
    )
    match = df[df["Branch Date"] == date_norm]
    if match.empty:
        return None
    row = match.iloc[0]
    return row["RT Driver Squad"], row["Release Version"]


# ---------------------------------------------------------------------
# Unit‑tests -----------------------------------------------------------
# ---------------------------------------------------------------------
import unittest
from io import BytesIO

class _PandocLoaderTests(unittest.TestCase):
    """
    Validate loader + parser.
    The test monkey‑patches pypandoc.convert_file so it works without pandoc.
    """

    @classmethod
    def setUpClass(cls):
        # Create a Word document in memory
        cls.doc = Document()
        tbl = cls.doc.add_table(rows=1, cols=3)
        tbl.rows[0].cells[0].text = "release version train"
        tbl.rows[0].cells[1].text = "RTDriverSquadTeam"
        tbl.rows[0].cells[2].text = "BranchDate(UTC)"
        data_row = tbl.add_row().cells
        data_row[0].text, data_row[1].text, data_row[2].text = "30.0", "Athena", "07 Jul 2025"

        # Save one copy as .docx
        cls.docx_path = tempfile.mktemp(suffix=".docx")
        cls.doc.save(cls.docx_path)

        # Save second copy as .doc (actually a docx inside, but good enough)
        cls.doc_path = tempfile.mktemp(suffix=".doc")
        cls.doc.save(cls.doc_path)

        # Monkey‑patch pypandoc.convert_file
        import types, sys
        fake_pandoc = types.ModuleType("pypandoc")
        sys.modules["pypandoc"] = fake_pandoc

        def _fake_convert_file(src, to, outputfile):
            # Simply copy the input file (already really a docx) to output
            shutil.copyfile(src, outputfile)
            return outputfile

        fake_pandoc.convert_file = _fake_convert_file

    @classmethod
    def tearDownClass(cls):
        os.unlink(cls.docx_path)
        os.unlink(cls.doc_path)

    # ------------------------------------------------------------
    def test_load_docx(self):
        df = read_release_table(self.__class__.docx_path)
        self.assertEqual(get_squad_name(df, "07 Jul 2025"), ("Athena", "30.0"))

    def test_load_doc(self):
        df = read_release_table(self.__class__.doc_path)
        self.assertEqual(get_squad_name(df, "07 Jul 2025"), ("Athena", "30.0"))

    def test_missing_file(self):
        with self.assertRaises(FileNotFoundError):
            read_release_table("/nonexistent/file.docx")

    def test_no_table(self):
        # Create empty docx
        empty_path = tempfile.mktemp(suffix=".docx")
        Document().save(empty_path)
        with self.assertRaises(ValueError):
            read_release_table(empty_path)
        os.unlink(empty_path)


unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(_PandocLoaderTests))
